---
title: "Méthodologie"
output: html_document
---

<p style='text-align: justify;'> 
On parle depuis quelques années du phénomène de Big Data, que l'on traduit souvent par "données massives" ou "grosses données". Les données massives est un avantage pour le statisticien ou le data scientist car elles augmentent le nombre d'exemples pour la modélisation. 
Cependant, si le nombre de variables augmente, il faut augmenter le nombre d'observations exponentiellement pour avoir la même précision.La multiplication des dimensions rend l'analyse de plus en plus complexe : c'est ce qu'on appelle le fléau de la dimension.
Une solution à ce fléau consiste à faire appel  des méthodes de réduction de dimension. C'est ce dont nous allons voir avec les méthodes de pénalisation et d'agrégation.
</p>
 
# **Méthodes de pénalisation** : 

Les méthodes de pénalisation permettent de régler le problème de la multicolinéarité entre les variables dû aux données massives.

Pour cela, nous allons introduire le paramètre $\lambda$ dans la régression pour permettre de réduire la variabilité de l'estimateur MCO.
Le $\lambda$ contrôle l'amplitude des coefficients ou leur niveau de rétrécissement.

Lorsque $\lambda$ tend vers 0, le terme de pénalité n'a aucun effet, la régression produira les coefficient classiques des MCO. Lorsque $\lambda$ tend vers infini, l'impact de la pénalité augmente et les coefficients se rapprochent de 0.

La valeur optimale du paramètre de régularisation $\lambda$ peut être obtenue par validation croisée.


## Régression Ridge : 

La régression Ridge correspond à la méthode des MCO sous une contrainte d'inégalité portant sur les coefficients : 

$$
\left\{\begin{array}{l}
\hat{\beta}=\underset{\beta}{\arg \min } \sum_{i=1}^{n}\left(y_{i}-x_{i} \beta\right)^{2} \\
\text { s.c. } \sum_{j=1}^{p} \beta_{j}^{2} \leq t
\end{array}\right.
$$

La fonction objective à minimiser équivaut à : 

$$
\operatorname{PRSS}(\beta)=(y-X \beta)^{T}(y-X \beta)+\lambda\ \sum_{j=1}^{p} \beta_{j}^{2}
$$

Cette fonction à la particulatité de ne pas annuler les coefficients $\beta$ mais de les réduire et de les faire tendre vers 0.


## Régression Lasso : 

Cette pénalisation est adaptée lorsque p ≥ n. Elle peut être utile aussi dans le cas p < n pour éviter sur-ajustement via la sélection de variables, dès lors que p est élevé. 

La régression Lasso correspond à la méthode des MCO sous une contrainte d'une norme 1 : 

$$
\left\{\begin{array}{l}
\hat{\beta}=\underset{\beta}{\arg \min } \sum_{i=1}^{n}\left(y_{i}-x_{i} \beta\right)^{2} \\
\text { s.c. } \sum_{j=1}^{p} |\beta_{j}| \leq t
\end{array}\right.
$$

La fonction objective à minimiser équivaut à : 

$$
\operatorname{PRSS}(\beta)=(y-X \beta)^{T}(y-X \beta)+\lambda\ \sum_{j=1}^{p} |\beta_{j}|
$$

<p style='text-align: justify;'> 
Contrairement à la régression Ridge qui réduit les coefficients vers 0 sans les annuler, la régression Lasso réduit les coefficient les plus élevés vers 0 et annule les coefficient les plus failes.
La régression Lasso procède donc à la fois à de la sélection et à la régularisation des coefficients.
</p>


## Elastic-Net :
La régression Elastic Net combine à la fois les pénalisations Ridge et Lasso présentées plus haut. 

La fonction objective à minimiser équivaut à : 

$$
\operatorname{PRSS}(\beta)=(y-X \beta)^{T}(y-X \beta)+\lambda_2\ \sum_{j=1}^{p} \beta_{j}^{2} + \lambda_1\ \sum_{j=1}^{p} |\beta_{j}|
$$

avec $\lambda_1$ et $\lambda_2$ les deux paramètres de régularisation Lasso et Ridge respectivement.

Cette méthode permet de faire de la sélection de plus de n variables et faire de la sélection groupée de variables corrélées dès lors qu'une est admise dans le modèle. 


## Adaptive Lasso : 

L'estimateur est construit comme le Lasso, mais en réalisant une pénalisation différente pour chaque coefficient. Cette pénalisation est d'autant plus importante que le coefficient semble proche de 0.

Cette méthode à la capacité de mieux sélectionner les variables pertinentes car elle permet d'annuler le risque de selectionner des variables correspondant à du bruit. 

La fonction objective à minimiser équivaut à : 
$$
\operatorname{PRSS}(\beta)=(y-X \beta)^{T}(y-X \beta)+ \lambda\ \sum_{j=1}^{p} w_j  |\beta_{j}|
$$
$$ w_j= \frac{1}{|\hat{\beta_{j}}|^{v}}$$ 
Avec $\hat{\beta_{j}}$ l'estimateur MCO univarié de $\beta_{j}$ et $v>0$ 




# **Méthodes d'agrégation** : 

## Random Forest :

Un random forest est constitué d'un ensemble d'arbres de décision indépendants.

```{r pressure, echo=FALSE, out.width = '35%'}
knitr::include_graphics("RAN1.png")
```



Le défaut majeur de l'arbre de décision est que sa performance est fortement dépendante de l'échantillon de données de départ. Par exemple, l'ajout de quelques nouvelles données dans la base d'apprentissage peut modifier radicalement le modèle et les résultats.

Pour lutter contre ce défaut, on peut utiliser une multitude d’arbres : une forêt d'arbres.

Les random forests réduisent la variance observée dans les arbres de décision :

  - En utilisant différents échantillons pour l’entraînement,
  - En spécifiant des sous-ensembles de caractéristiques aléatoires,
  - En construisant et combinant de petits arbres (peu profonds)

La prédiction faite par le random forest pour des données inconnues est alors la moyenne (ou le vote, dans le cas d'un problème de classification) de tous les arbres.

```{r pressure2, echo=FALSE, out.width = '50%'}
knitr::include_graphics("images/RAN2.png")
```


## Boosting :

Pour le Boosting, les algorithmes ne sont plus indépendants. Au contraire, chaque « weak learner » est entraîné pour corriger les erreurs des « weak learner » précédents.

## AdaBoost  :

Pour demander la prédiction d’Adaboost sur une observation, il faut interroger chaque « weak learner » et pondérer chaque réponse en fonction de la note qu’ils ont obtenu. 
La prédiction du « strong learner » sera la moyenne de toutes les réponses des « weak learner ».

```{r pressure3, echo=FALSE, out.width = '50%'}
knitr::include_graphics("images/RAN2.png")
```








## Gradient Boosting :

L’algorithme de Gradient Boosting a beaucoup de points communs avec Adaboost, comme Adaboost, chaque “weak learner” est entraîné pour corriger les erreurs des “weak learners” précédents.

Néanmoins, contrairement à Adaboost, les “weak learners” ont tous autant de poids dans le système de votation, peu importe leur performance.








